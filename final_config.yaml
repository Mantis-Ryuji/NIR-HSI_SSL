seed: 42

chemomae:
  seq_len: 256
  d_model: 512
  nhead: 8
  num_layers: 8
  dim_feedforward: 2048
  dropout: 0.1
  decoder_num_layers: 1
  latent_dim: 32
  n_patches: 16
  n_mask: ?????

training:
  dataLoader:
    batch_size: 4096         
    num_workers: 8           
    pin_memory: true         
    persistent_workers: true 

  optimizer:
    base_lr: 5e-4
    weight_decay: 1e-3 
    betas: [0.9, 0.95] 
    eps: 1.0e-8 

  scheduler: # warmup + cosine annealing
    warmup_epochs: 2 
    min_lr_scale: 0.02      # 最終LRは base_lr×0.02。
    
  trainer:
    config:
      out_dir: "runs/final/mae"
      device: "cuda"
      amp: True
      amp_dtype: "bf16"
      enable_tf32: False
      grad_clip: 1.0
      use_ema: True
      ema_decay: 0.999
      loss_type: "sse"
      reduction: "batch_mean"
      early_stop_patience: 20
      early_stop_start_ratio: 0.5
      early_stop_min_delta: 0.0
      resume_from: "auto"
    fit:
      epochs: 200

evaluation:
  # "runs/final/pca下に weight を保存"
  extrinsic_pca:
    n_components: 32
    center: False
    renorm: True
    method: "svd"
    device: "cuda"

  mlp:
    # "runs/final/eval/( raw | pca | mae )/each_task下に weight, result を保存"
    width: 256
    depth: 2
    dropout: 0.0
    activation: "gelu"
    norm: "layernorm"
    residual: True
    epochs: 20
    lr: 5e-4
    weight_decay: 1e-4
    optimizer: adamw"
    grad_clip_norm: 1.0
    device: "cuda"
    amp: False
    early_stopping: True
    patience: 5
    min_delta: 0.0
    restore_best: True
  
clustering:
  # "runs/final/clustering"下に weight, report を保存
  k_max: 100
  chunk: 5000000